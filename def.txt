classtorch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)

Parameters:

in_channels (int) – Number of channels in the input image
out_channels (int) – Number of channels produced by the convolution
kernel_size (intortuple) – Size of the convolving kernel
stride (intortuple,optional) – Stride of the convolution. Default: 1
padding (intortuple,optional) – Zero-padding added to both sides of the input. Default: 0
dilation (intortuple,optional) – Spacing between kernel elements. Default: 1
groups (int,optional) – Number of blocked connections from input channels to output channels. Default: 1
bias (bool,optional) – If True, adds a learnable bias to the output. Default: True

//#####################################################
            nn.Conv2d(3,96,(11, 11),(4, 4)),
	    //去掉輸入小於0的部分
	    nn.ReLU(inplace=True),

	    //1*1 convolution
	    nn.Conv2d(96,96,(1, 1)),
	    nn.ReLU(inplace=True),

	    nn.Conv2d(96,96,(1, 1)),
	    nn.ReLU(inplace=True),
            pool2d,
//#####################################################
	    nn.Conv2d(96,256,(5, 5),(1, 1),(2, 2)),
	    nn.ReLU(inplace=True),
	    nn.Conv2d(256,256,(1, 1)),
	    nn.ReLU(inplace=True),
	    nn.Conv2d(256,256,(1, 1)),
	    nn.ReLU(inplace=True),
            pool2d,
//#####################################################
	    nn.Conv2d(256,384,(3, 3),(1, 1),(1, 1)),
	    nn.ReLU(inplace=True),
	    nn.Conv2d(384,384,(1, 1)),
	    nn.ReLU(inplace=True),
	    nn.Conv2d(384,384,(1, 1)),
	    nn.ReLU(inplace=True),
            pool2d,
//#####################################################
               //Global Average Pooling

	    //減少過擬和
	    nn.Dropout(0.5),
	    nn.Conv2d(384,1024,(3, 3),(1, 1),(1, 1)),
	    nn.ReLU(inplace=True),
	    nn.Conv2d(1024,1024,(1, 1)),
	    nn.ReLU(inplace=True),
	    nn.Conv2d(1024,1000,(1, 1)),
	    nn.ReLU(inplace=True),
	    nn.AvgPool2d((6, 6),(1, 1),(0, 0),ceil_mode=True),
	    //選取機率最大的節點
	    nn.Softmax()